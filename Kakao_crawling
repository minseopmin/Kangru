import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd


    
def Kakao_data(food,area):
    options = Options()
    options.add_experimental_option('excludeSwitches', ['--proxy-server'])
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    driver=webdriver.Chrome(executable_path=ChromeDriverManager().install(), options=options)
    driver.maximize_window()
    driver.get("https://map.kakao.com/")
    search_box = driver.find_element(By.XPATH, '//*[@id="search.keyword.query"]')
    search_box.send_keys(f"{area}의 {food}")
    search_box.send_keys(Keys.ENTER)
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="info.search.place.list"]')))
    time.sleep(3)
    #장소명으로 검색 옵션
    #locationsearch =driver.find_element(By.XPATH, '//*[@id="info.searchHeader.message"]/div/div[2]/a')
    #time.sleep(3)
    #driver.execute_script("arguments[0].click();", locationsearch)
    #time.sleep(3)
    
    totalnum=driver.find_element(By.XPATH,'//*[@id="info.search.place.cnt"]').text
    totallist=range(1,int(totalnum)+1)
    #new_link = driver.find_elements(By.CSS_SELECTOR,//*[@id="info.search.place.list"]/li[1]/div[5]/div[4]/a[1])
    k=0
    l=0
    scorelist=[]
    storelist=[]
    phonelist=[]
    reviewlist=[]
    addresslist=[]
    phonelist=[]
    nextpage=[4,9,14,19,24,29,34]
    
    for i in totallist:
        i=i-15*k
        score_xpath='//*[@id="info.search.place.list"]/li['+str(i)+']/div[4]/span[1]/em'
        store_xpath='//*[@id="info.search.place.list"]/li['+str(i)+']/div[3]/strong/a[2]'
        review_xpath='//*[@id="info.search.place.list"]/li['+str(i)+']/div[4]/span[1]/a'
        address_xpath='//*[@id="info.search.place.list"]/li['+str(i)+']/div[5]/div[2]/p[1]'
        phone_xpath='//*[@id="info.search.place.list"]/li['+str(i)+']/div[5]/div[4]/span[1]'
        score=driver.find_element(By.XPATH,score_xpath).text
        store=driver.find_element(By.XPATH,store_xpath).text
        review=driver.find_element(By.XPATH,review_xpath).text
        address=driver.find_element(By.XPATH,address_xpath).text
        phone=driver.find_element(By.XPATH,phone_xpath).text
        
        scorelist.append(score)
        storelist.append(store)
        reviewlist.append(review)
        addresslist.append(address)
        phonelist.append(phone)
        if(len(scorelist)==15*(k+1)):
            if(k==0):
                moreinfo_selector='//*[@id="info.search.place.more"]'
            elif(k in nextpage):
                moreinfo_selector='//*[@id="info.search.page.next"]'
                l=l+1
            elif(k>35):
                break
            else:
                moreinfo_selector='//*[@id="info.search.page.no'+str(k+2-5*l)+'"]'
            moreinfo =driver.find_element(By.XPATH, moreinfo_selector)
            time.sleep(3)
            driver.execute_script("arguments[0].click();",moreinfo)
            time.sleep(3)
            print(k)
            k=k+1;
        elif(len(scorelist)==len(totallist)):
            print("모든 데이터 크롤링")
            
        else:
            pass
        
        
    print("total data :"+str(totalnum)+" but"+str(len(scorelist)))
    df = pd.DataFrame({'Store':storelist,'score':scorelist,'comment':reviewlist,'address':addresslist,'phone_num':phonelist})
    driver.quit()
    return df
            
loc_list=['서울 명동']
food_list=['불고기','떡볶이','삼겹살']

for loc in loc_list:
    for food in food_list:
        Kakao_data(food,loc).to_csv(loc+food+'.csv')
    
    
